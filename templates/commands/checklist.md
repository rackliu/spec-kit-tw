---
description: åŸºæ–¼ä½¿ç”¨è€…éœ€æ±‚ç‚ºç•¶å‰åŠŸèƒ½ç”Ÿæˆè‡ªå®šç¾©æª¢æŸ¥æ¸…å–®.
scripts:
  sh: scripts/bash/check-prerequisites.sh --json
  ps: scripts/powershell/check-prerequisites.ps1 -Json
---

## æ¸…å–®ç›®çš„: "éœ€æ±‚ç·¨å¯«çš„å–®å…ƒæ¸¬è©¦"

**æ ¸å¿ƒæ¦‚å¿µ**: æ¸…å–®æ˜¯**éœ€æ±‚ç·¨å¯«çš„å–®å…ƒæ¸¬è©¦** - å®ƒå€‘é©—è­‰ç‰¹å®šé ˜åŸŸä¸­éœ€æ±‚çš„å“è³ªã€æ¸…æ™°åº¦å’Œå®Œæ•´æ€§.

**ä¸ç”¨æ–¼é©—è­‰/æ¸¬è©¦**: 
- âŒ ä¸æ˜¯"é©—è­‰æŒ‰éˆ•é»é¸æ­£ç¢º"
- âŒ ä¸æ˜¯"æ¸¬è©¦éŒ¯èª¤è™•ç†æœ‰æ•ˆ"
- âŒ ä¸æ˜¯"ç¢ºèª API è¿”å› 200"
- âŒ ä¸æ˜¯æª¢æŸ¥ç¨‹å¼ç¢¼/å¯¦ç¾æ˜¯å¦ç¬¦åˆè¦æ ¼

**ç”¨æ–¼éœ€æ±‚å“è³ªé©—è­‰**: 
- âœ… "æ˜¯å¦ç‚ºæ‰€æœ‰å¡ç‰‡å‹åˆ¥å®šç¾©äº†è¦–è¦ºå±¤æ¬¡éœ€æ±‚ï¼Ÿ"(å®Œæ•´æ€§)
- âœ… "'çªå‡ºé¡¯ç¤º'æ˜¯å¦é€éå…·é«”å°ºå¯¸/ä½ç½®é€²è¡Œäº†é‡åŒ–ï¼Ÿ"(æ¸…æ™°åº¦)
- âœ… "æ‰€æœ‰äº’å‹•å…ƒç´ çš„æ‡¸åœç‹€æ…‹éœ€æ±‚æ˜¯å¦ä¸€è‡´ï¼Ÿ"(ä¸€è‡´æ€§)
- âœ… "æ˜¯å¦ç‚ºéµç›¤å°èˆªå®šç¾©äº†å¯è¨ªå•æ€§éœ€æ±‚ï¼Ÿ"(è¦†è“‹åº¦)
- âœ… "è¦æ ¼æ˜¯å¦å®šç¾©äº† logo å½±åƒè¼‰å…¥å¤±æ•—æ™‚çš„è™•ç†ï¼Ÿ"(é‚Šç·£æƒ…æ³)

**æ¯”å–»**: å¦‚æœä½ çš„è¦æ ¼æ˜¯ç”¨è‹±æ–‡ç·¨å¯«çš„ç¨‹å¼ç¢¼, é‚£éº¼æ¸…å–®å°±æ˜¯å®ƒçš„å–®å…ƒæ¸¬è©¦å¥—ä»¶. ä½ æ¸¬è©¦çš„æ˜¯éœ€æ±‚æ˜¯å¦ç·¨å¯«è‰¯å¥½ã€å®Œæ•´ã€æ˜ç¢ºä¸¦æº–å‚™å¥½å¯¦æ–½ - è€Œä¸æ˜¯å¯¦ç¾æ˜¯å¦æœ‰æ•ˆ.

## ä½¿ç”¨è€…è¼¸å…¥

```text
$ARGUMENTS
```

åœ¨ç¹¼çºŒä¹‹å‰, ä½ **å¿…é ˆ**è€ƒæ…®ä½¿ç”¨è€…è¼¸å…¥(å¦‚æœä¸ç‚ºç©º).

## åŸ·è¡Œæ­¥é©Ÿ

1. **è¨­å®š**: å¾å€‰åº«æ ¹ç›®éŒ„åŸ·è¡Œ `{SCRIPT}` ä¸¦è§£æJSONä»¥ç²å–FEATURE_DIRå’ŒAVAILABLE_DOCSåˆ—è¡¨.
   - æ‰€æœ‰æª”æ¡ˆè·¯å¾‘å¿…é ˆæ˜¯çµ•å°è·¯å¾‘.
   - å°æ–¼å¼•æ•¸ä¸­çš„å–®å¼•è™Ÿå¦‚"I'm Groot", ä½¿ç”¨è½‰ç¾©èªæ³•: ä¾‹å¦‚ 'I'\''m Groot'(æˆ–è€…å„˜å¯èƒ½ä½¿ç”¨é›™å¼•è™Ÿ: "I'm Groot").

2. **æ¾„æ¸…æ„åœ–(å‹•æ…‹)**: æ¨å°æœ€å¤šä¸‰å€‹åˆå§‹ä¸Šä¸‹æ–‡æ¾„æ¸…å•é¡Œ(ç„¡é ç·¨ç›®éŒ„). å®ƒå€‘å¿…é ˆ: 
   - å¾ä½¿ç”¨è€…çš„è¡¨è¿° + å¾è¦æ ¼/è¨ˆåŠƒ/ä»»å‹™ä¸­æå–çš„è¨Šè™Ÿç”Ÿæˆ
   - åªè©¢å•å¯¦è³ªä¸Šæ”¹è®Šæ¸…å–®å…§å®¹çš„è³‡è¨Š
   - å¦‚æœåœ¨`$ARGUMENTS`ä¸­å·²ç¶“æ˜ç¢º, å‰‡å–®ç¨è·³é
   - å„ªå…ˆè€ƒæ…®ç²¾ç¢ºæ€§è€Œéå»£åº¦

   Generation algorithm:
   1. Extract signals: feature domain keywords (e.g., auth, latency, UX, API), risk indicators ("critical", "must", "compliance"), stakeholder hints ("QA", "review", "security team"), and explicit deliverables ("a11y", "rollback", "contracts").
   2. Cluster signals into candidate focus areas (max 4) ranked by relevance.
   3. Identify probable audience & timing (author, reviewer, QA, release) if not explicit.
   4. Detect missing dimensions: scope breadth, depth/rigor, risk emphasis, exclusion boundaries, measurable acceptance criteria.
   5. Formulate questions chosen from these archetypes:
      - Scope refinement (e.g., "Should this include integration touchpoints with X and Y or stay limited to local module correctness?")
      - Risk prioritization (e.g., "Which of these potential risk areas should receive mandatory gating checks?")
      - Depth calibration (e.g., "Is this a lightweight pre-commit sanity list or a formal release gate?")
      - Audience framing (e.g., "Will this be used by the author only or peers during PR review?")
      - Boundary exclusion (e.g., "Should we explicitly exclude performance tuning items this round?")
      - Scenario class gap (e.g., "No recovery flows detectedâ€”are rollback / partial failure paths in scope?")

   Question formatting rules:
   - If presenting options, generate a compact table with columns: Option | Candidate | Why It Matters
   - Limit to Aâ€“E options maximum; omit table if a free-form answer is clearer
   - Never ask the user to restate what they already said
   - Avoid speculative categories (no hallucination). If uncertain, ask explicitly: "Confirm whether X belongs in scope."

   Defaults when interaction impossible:
   - Depth: Standard
   - Audience: Reviewer (PR) if code-related; Author otherwise
   - Focus: Top 2 relevance clusters

   Output the questions (label Q1/Q2/Q3). After answers: if â‰¥2 scenario classes (Alternate / Exception / Recovery / Non-Functional domain) remain unclear, you MAY ask up to TWO more targeted followâ€‘ups (Q4/Q5) with a one-line justification each (e.g., "Unresolved recovery path risk"). Do not exceed five total questions. Skip escalation if user explicitly declines more.

3. **ç†è§£ä½¿ç”¨è€…è«‹æ±‚**: çµåˆ `$ARGUMENTS` + æ¾„æ¸…ç­”æ¡ˆ: 
   - æ¨å°æ¸…å–®ä¸»é¡Œ(ä¾‹å¦‚: security, review, deploy, ux)
   - æ•´åˆä½¿ç”¨è€…æ˜ç¢ºæåˆ°çš„å¿…éœ€å°ˆæ¡ˆ
   - å°‡ç„¦é»é¸æ“‡å°æ˜ åˆ°é¡åˆ¥æ¡†æ¶
   - å¾è¦æ ¼/è¨ˆåŠƒ/ä»»å‹™ä¸­æ¨æ–·ä»»ä½•ç¼ºå¤±çš„ä¸Šä¸‹æ–‡(ä¸è¦è™›æ§‹)

4. **è¼‰å…¥åŠŸèƒ½ä¸Šä¸‹æ–‡**: å¾ FEATURE_DIR è®€å–: 
   - spec.md: åŠŸèƒ½éœ€æ±‚å’Œç¯„åœ
   - plan.md(å¦‚æœå­˜åœ¨): æŠ€è¡“ç´°ç¯€ã€ä¾è³´é—œä¿‚
   - tasks.md(å¦‚æœå­˜åœ¨): å¯¦æ–½ä»»å‹™

   **ä¸Šä¸‹æ–‡è¼‰å…¥ç­–ç•¥**: 
   - åƒ…è¼‰å…¥èˆ‡æ´»å‹•ç„¦é»å€åŸŸç›¸é—œçš„å¿…è¦éƒ¨åˆ†(é¿å…å…¨æ–‡è½‰å„²)
   - å„ªå…ˆå°‡é•·éƒ¨åˆ†ç¸½çµç‚ºç°¡æ½”çš„å ´æ™¯/éœ€æ±‚è¦é»
   - ä½¿ç”¨æ¼¸é€²å¼æŠ«éœ²: åƒ…åœ¨æª¢æ¸¬åˆ°å·®è·æ™‚æ–°å¢å¾ŒçºŒæª¢ç´¢
   - å¦‚æœæºæ–‡ä»¶å¾ˆå¤§, ç”Ÿæˆè‡¨æ™‚æ‘˜è¦å°ˆæ¡ˆè€Œä¸æ˜¯åµŒå…¥åŸå§‹æ–‡å­—

5. **ç”Ÿæˆæ¸…å–®** - å»ºç«‹"éœ€æ±‚çš„å–®å…ƒæ¸¬è©¦": 
   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist
   - Generate unique checklist filename:
     - Use short, descriptive name based on domain (e.g., `ux.md`, `api.md`, `security.md`)
     - Format: `[domain].md` 
     - If file exists, append to existing file
   - Number items sequentially starting from CHK001
   - Each `/speckit.checklist` run creates a NEW file (never overwrites existing checklists)

   **æ ¸å¿ƒåŸå‰‡ - æ¸¬è©¦éœ€æ±‚, è€Œéå¯¦ç¾**: 
   æ¯å€‹æ¸…å–®å°ˆæ¡ˆå¿…é ˆè©•ä¼°éœ€æ±‚æœ¬èº«, æª¢æŸ¥: 
   - **å®Œæ•´æ€§**: æ‰€æœ‰å¿…è¦çš„éœ€æ±‚æ˜¯å¦å­˜åœ¨ï¼Ÿ
   - **æ¸…æ™°åº¦**: éœ€æ±‚æ˜¯å¦æ˜ç¢ºç„¡æ­§ç¾©ä¸”å…·é«”ï¼Ÿ
   - **ä¸€è‡´æ€§**: éœ€æ±‚ä¹‹é–“æ˜¯å¦ç›¸äº’ä¸€è‡´ï¼Ÿ
   - **å¯æ¸¬é‡æ€§**: éœ€æ±‚æ˜¯å¦å¯ä»¥å®¢è§€é©—è­‰ï¼Ÿ
   - **è¦†è“‹åº¦**: æ˜¯å¦æ¶µè“‹äº†æ‰€æœ‰å ´æ™¯/é‚Šç·£æƒ…æ³ï¼Ÿ

   **é¡åˆ¥çµæ§‹** - æŒ‰éœ€æ±‚å“è³ªç¶­åº¦åˆ†çµ„å°ˆæ¡ˆ: 
   - **éœ€æ±‚å®Œæ•´æ€§**(æ‰€æœ‰å¿…è¦çš„éœ€æ±‚æ˜¯å¦å·²è¨˜éŒ„ï¼Ÿ)
   - **éœ€æ±‚æ¸…æ™°åº¦**(éœ€æ±‚æ˜¯å¦å…·é«”ä¸”ç„¡æ­§ç¾©ï¼Ÿ)
   - **éœ€æ±‚ä¸€è‡´æ€§**(éœ€æ±‚æ˜¯å¦ä¸€è‡´ä¸”ç„¡è¡çªï¼Ÿ)
   - **é©—æ”¶æ¨™æº–å“è³ª**(æˆåŠŸæ¨™æº–æ˜¯å¦å¯æ¸¬é‡ï¼Ÿ)
   - **å ´æ™¯è¦†è“‹åº¦**(æ˜¯å¦æ¶µè“‹äº†æ‰€æœ‰æµç¨‹/æƒ…æ³ï¼Ÿ)
   - **é‚Šç·£æƒ…æ³è¦†è“‹åº¦**(æ˜¯å¦å®šç¾©äº†é‚Šç•Œæ¢ä»¶ï¼Ÿ)
   - **éåŠŸèƒ½æ€§éœ€æ±‚**(æ•ˆèƒ½ã€å®‰å…¨æ€§ã€å¯è¨ªå•æ€§ç­‰ - æ˜¯å¦å·²æŒ‡å®šï¼Ÿ)
   - **ä¾è³´é—œä¿‚å’Œå‡è¨­**(æ˜¯å¦å·²è¨˜éŒ„å’Œé©—è­‰ï¼Ÿ)
   - **æ­§ç¾©å’Œè¡çª**(ä»€éº¼ NEEDS CLARIFICATIONï¼Ÿ)

   **å¦‚ä½•ç·¨å¯«æ¸…å–®å°ˆæ¡ˆ - "éœ€æ±‚ç·¨å¯«çš„å–®å…ƒæ¸¬è©¦"**: 
   
   âŒ **WRONG** (Testing implementation):
   - "Verify landing page displays 3 episode cards"
   - "Test hover states work on desktop"
   - "Confirm logo click navigates home"
   
   âœ… **CORRECT** (Testing requirements quality):
   - "Are the exact number and layout of featured episodes specified?" [Completeness]
   - "Is 'prominent display' quantified with specific sizing/positioning?" [Clarity]
   - "Are hover state requirements consistent across all interactive elements?" [Consistency]
   - "Are keyboard navigation requirements defined for all interactive UI?" [Coverage]
   - "Is the fallback behavior specified when logo image fails to load?" [Edge Cases]
   - "Are loading states defined for asynchronous episode data?" [Completeness]
   - "Does the spec define visual hierarchy for competing UI elements?" [Clarity]
   
   **å°ˆæ¡ˆçµæ§‹**: 
   Each item should follow this pattern:
   - Question format asking about requirement quality
   - Focus on what's WRITTEN (or not written) in the spec/plan
   - Include quality dimension in brackets [Completeness/Clarity/Consistency/etc.]
   - Reference spec section `[Spec Â§X.Y]` when checking existing requirements
   - Use `[Gap]` marker when checking for missing requirements
   
   **æŒ‰å“è³ªç¶­åº¦åˆ†é¡çš„ç¯„ä¾‹**: 
   
   å®Œæ•´æ€§: 
   - "Are error handling requirements defined for all API failure modes? [Gap]"
   - "Are accessibility requirements specified for all interactive elements? [Completeness]"
   - "Are mobile breakpoint requirements defined for responsive layouts? [Gap]"
   
   æ¸…æ™°åº¦: 
   - "Is 'fast loading' quantified with specific timing thresholds? [Clarity, Spec Â§NFR-2]"
   - "Are 'related episodes' selection criteria explicitly defined? [Clarity, Spec Â§FR-5]"
   - "Is 'prominent' defined with measurable visual properties? [Ambiguity, Spec Â§FR-4]"
   
   ä¸€è‡´æ€§: 
   - "Do navigation requirements align across all pages? [Consistency, Spec Â§FR-10]"
   - "Are card component requirements consistent between landing and detail pages? [Consistency]"
   
   è¦†è“‹åº¦: 
   - "Are requirements defined for zero-state scenarios (no episodes)? [Coverage, Edge Case]"
   - "Are concurrent user interaction scenarios addressed? [Coverage, Gap]"
   - "Are requirements specified for partial data loading failures? [Coverage, Exception Flow]"
   
   å¯æ¸¬é‡æ€§: 
   - "Are visual hierarchy requirements measurable/testable? [Acceptance Criteria, Spec Â§FR-1]"
   - "Can 'balanced visual weight' be objectively verified? [Measurability, Spec Â§FR-2]"

   **å ´æ™¯åˆ†é¡èˆ‡è¦†è“‹åº¦**(éœ€æ±‚å“è³ªç„¦é»): 
   - Check if requirements exist for: Primary, Alternate, Exception/Error, Recovery, Non-Functional scenarios
   - For each scenario class, ask: "Are [scenario type] requirements complete, clear, and consistent?"
   - If scenario class missing: "Are [scenario type] requirements intentionally excluded or missing? [Gap]"
   - Include resilience/rollback when state mutation occurs: "Are rollback requirements defined for migration failures? [Gap]"

   **å¯è¿½æº¯æ€§è¦æ±‚**: 
   - MINIMUM: â‰¥80% of items MUST include at least one traceability reference
   - Each item should reference: spec section `[Spec Â§X.Y]`, or use markers: `[Gap]`, `[Ambiguity]`, `[Conflict]`, `[Assumption]`
   - If no ID system exists: "Is a requirement & acceptance criteria ID scheme established? [Traceability]"

   **ç™¼ç¾å’Œè§£æ±ºå•é¡Œ**(éœ€æ±‚å“è³ªå•é¡Œ): 
   Ask questions about the requirements themselves:
   - Ambiguities: "Is the term 'fast' quantified with specific metrics? [Ambiguity, Spec Â§NFR-1]"
   - Conflicts: "Do navigation requirements conflict between Â§FR-10 and Â§FR-10a? [Conflict]"
   - Assumptions: "Is the assumption of 'always available podcast API' validated? [Assumption]"
   - Dependencies: "Are external podcast API requirements documented? [Dependency, Gap]"
   - Missing definitions: "Is 'visual hierarchy' defined with measurable criteria? [Gap]"

   **å…§å®¹æ•´åˆ**: 
   - Soft cap: If raw candidate items > 40, prioritize by risk/impact
   - Merge near-duplicates checking the same requirement aspect
   - If >5 low-impact edge cases, create one item: "Are edge cases X, Y, Z addressed in requirements? [Coverage]"

   **ğŸš« ABSOLUTELY PROHIBITED** - These make it an implementation test, not a requirements test:
   - âŒ Any item starting with "Verify", "Test", "Confirm", "Check" + implementation behavior
   - âŒ References to code execution, user actions, system behavior
   - âŒ "Displays correctly", "works properly", "functions as expected"
   - âŒ "Click", "navigate", "render", "load", "execute"
   - âŒ Test cases, test plans, QA procedures
   - âŒ Implementation details (frameworks, APIs, algorithms)
   
   **âœ… REQUIRED PATTERNS** - These test requirements quality:
   - âœ… "Are [requirement type] defined/specified/documented for [scenario]?"
   - âœ… "Is [vague term] quantified/clarified with specific criteria?"
   - âœ… "Are requirements consistent between [section A] and [section B]?"
   - âœ… "Can [requirement] be objectively measured/verified?"
   - âœ… "Are [edge cases/scenarios] addressed in requirements?"
   - âœ… "Does the spec define [missing aspect]?"

6. **çµæ§‹åƒè€ƒ**: æŒ‰ç…§ `templates/checklist-template.md` ä¸­çš„è¦æ ¼æ¨¡æ¿ç”Ÿæˆæ¸…å–®, åŒ…æ‹¬æ¨™é¡Œã€å…ƒéƒ¨åˆ†ã€é¡åˆ¥æ¨™é¡Œå’Œ ID æ ¼å¼. å¦‚æœæ¨¡æ¿ä¸å¯ç”¨, ä½¿ç”¨: H1 æ¨™é¡Œã€purpose/created å…ƒè¡Œã€åŒ…å« `- [ ] CHK### <requirement item>` è¡Œçš„ `##` é¡åˆ¥éƒ¨åˆ†, ID å¾ CHK001 é–‹å§‹å…¨åŸŸæ€§éå¢.

7. **å ±å‘Š**: è¼¸å‡ºå»ºç«‹æ¸…å–®çš„å®Œæ•´è·¯å¾‘ã€å°ˆæ¡ˆæ•¸é‡, ä¸¦æé†’ä½¿ç”¨è€…æ¯æ¬¡åŸ·è¡Œéƒ½æœƒå»ºç«‹æ–°æª”æ¡ˆ. ç¸½çµ: 
   - é¸æ“‡çš„ç„¦é»å€åŸŸ
   - æ·±åº¦ç´šåˆ¥
   - åŸ·è¡Œè€…/æ™‚é–“
   - ä»»ä½•æ•´åˆçš„ä½¿ç”¨è€…æ˜ç¢ºæŒ‡å®šçš„å¿…éœ€å°ˆæ¡ˆ

**é‡è¦èªªæ˜**: æ¯æ¬¡ `/speckit.checklist` å‘½ä»¤å‘¼å«éƒ½æœƒå»ºç«‹ä¸€å€‹ä½¿ç”¨ç°¡çŸ­æè¿°æ€§åç¨±çš„æ¸…å–®æª”æ¡ˆ, é™¤éæª”æ¡ˆå·²å­˜åœ¨. é€™å…è¨±: 

- å»ºç«‹å¤šç¨®ä¸åŒå‹åˆ¥çš„æ¸…å–®(ä¾‹å¦‚: `ux.md`, `test.md`, `security.md`)
- ä½¿ç”¨ç°¡å–®ã€æ˜“è¨˜çš„æª”åä¾†è¡¨æ˜æ¸…å–®ç”¨é€”
- åœ¨ `checklists/` è³‡æ–™å¤¾ä¸­è¼•é¬†è­˜åˆ¥å’Œå°èˆª

ç‚ºé¿å…æ··äº‚, è«‹ä½¿ç”¨æè¿°æ€§å‹åˆ¥, ä¸¦åœ¨å®Œæˆå¾Œæ¸…ç†éæ™‚çš„æ¸…å–®.

## ç¯„ä¾‹æ¸…å–®å‹åˆ¥å’Œç¯„ä¾‹å°ˆæ¡ˆ

**UX éœ€æ±‚å“è³ª**: `ux.md`

ç¯„ä¾‹å°ˆæ¡ˆ(æ¸¬è©¦éœ€æ±‚, è€Œéå¯¦ç¾): 
- "Are visual hierarchy requirements defined with measurable criteria? [Clarity, Spec Â§FR-1]"
- "Is the number and positioning of UI elements explicitly specified? [Completeness, Spec Â§FR-1]"
- "Are interaction state requirements (hover, focus, active) consistently defined? [Consistency]"
- "Are accessibility requirements specified for all interactive elements? [Coverage, Gap]"
- "Is fallback behavior defined when images fail to load? [Edge Case, Gap]"
- "Can 'prominent display' be objectively measured? [Measurability, Spec Â§FR-4]"

**API éœ€æ±‚å“è³ª**: `api.md`

ç¯„ä¾‹å°ˆæ¡ˆ: 
- "Are error response formats specified for all failure scenarios? [Completeness]"
- "Are rate limiting requirements quantified with specific thresholds? [Clarity]"
- "Are authentication requirements consistent across all endpoints? [Consistency]"
- "Are retry/timeout requirements defined for external dependencies? [Coverage, Gap]"
- "Is versioning strategy documented in requirements? [Gap]"

**æ•ˆèƒ½éœ€æ±‚å“è³ª**: `performance.md`

ç¯„ä¾‹å°ˆæ¡ˆ: 
- "Are performance requirements quantified with specific metrics? [Clarity]"
- "Are performance targets defined for all critical user journeys? [Coverage]"
- "Are performance requirements under different load conditions specified? [Completeness]"
- "Can performance requirements be objectively measured? [Measurability]"
- "Are degradation requirements defined for high-load scenarios? [Edge Case, Gap]"

**å®‰å…¨éœ€æ±‚å“è³ª**: `security.md`

ç¯„ä¾‹å°ˆæ¡ˆ: 
- "Are authentication requirements specified for all protected resources? [Coverage]"
- "Are data protection requirements defined for sensitive information? [Completeness]"
- "Is the threat model documented and requirements aligned to it? [Traceability]"
- "Are security requirements consistent with compliance obligations? [Consistency]"
- "Are security failure/breach response requirements defined? [Gap, Exception Flow]"

## åä¾‹: ä»€éº¼ä¸è¦åš

**âŒ éŒ¯èª¤ - é€™äº›æ¸¬è©¦å¯¦ç¾, è€Œééœ€æ±‚: **

```markdown
- [ ] CHK001 - Verify landing page displays 3 episode cards [Spec Â§FR-001]
- [ ] CHK002 - Test hover states work correctly on desktop [Spec Â§FR-003]
- [ ] CHK003 - Confirm logo click navigates to home page [Spec Â§FR-010]
- [ ] CHK004 - Check that related episodes section shows 3-5 items [Spec Â§FR-005]
```

**âœ… æ­£ç¢º - é€™äº›æ¸¬è©¦éœ€æ±‚å“è³ª: **

```markdown
- [ ] CHK001 - Are the number and layout of featured episodes explicitly specified? [Completeness, Spec Â§FR-001]
- [ ] CHK002 - Are hover state requirements consistently defined for all interactive elements? [Consistency, Spec Â§FR-003]
- [ ] CHK003 - Are navigation requirements clear for all clickable brand elements? [Clarity, Spec Â§FR-010]
- [ ] CHK004 - Is the selection criteria for related episodes documented? [Gap, Spec Â§FR-005]
- [ ] CHK005 - Are loading state requirements defined for asynchronous episode data? [Gap]
- [ ] CHK006 - Can "visual hierarchy" requirements be objectively measured? [Measurability, Spec Â§FR-001]
```

**é—œéµå€åˆ¥: **
- éŒ¯èª¤: æ¸¬è©¦ç³»çµ±æ˜¯å¦æ­£å¸¸å·¥ä½œ
- æ­£ç¢º: æ¸¬è©¦éœ€æ±‚æ˜¯å¦ç·¨å¯«æ­£ç¢º
- éŒ¯èª¤: é©—è­‰è¡Œç‚º
- æ­£ç¢º: é©—è­‰éœ€æ±‚å“è³ª
- éŒ¯èª¤: "å®ƒæ˜¯å¦åš Xï¼Ÿ"
- æ­£ç¢º: "X æ˜¯å¦æ˜ç¢ºæŒ‡å®šï¼Ÿ"
